{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64580351-7a67-4d42-936a-63c6c36e7082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconder\\envs\\dots_ocr\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4514d027-6961-410f-8c20-737e973a0293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n",
      "flash attention not available! fallback to eager implementation \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.22s/it]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# 本地模型路径（使用绝对路径更稳妥，示例路径需替换为你的实际路径）\n",
    "model_path = \"../weights/DotsOCR\"  # Windows示例\n",
    "# model_path = \"/home/你的用户名/dots.ocr/weights/DotsOCR\"  # Linux/Mac示例\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,  # 本地路径直接传入\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,  # 必须开启\n",
    "    load_in_8bit=True\n",
    ")\n",
    "\n",
    "# 加载处理器\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "466d846c-c1d5-4cf7-a731-3105e03c2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用项目自带的测试图片\n",
    "image_path = \"C:/Users/fsq/Desktop/1.png\"\n",
    "\n",
    "# 模型指令（固定格式）\n",
    "prompt = \"\"\"Please output the layout information from the PDF image, including each layout element's bbox, its category, and the corresponding text content within the bbox.\n",
    "\n",
    "1. Bbox format: [x1, y1, x2, y2]\n",
    "2. Layout Categories: ['Caption', 'Footnote', 'Formula', 'List-item', 'Page-footer', 'Page-header', 'Picture', 'Section-header', 'Table', 'Text', 'Title']\n",
    "3. Text Extraction & Formatting Rules:\n",
    "    - Picture: For the 'Picture' category, the text field should be omitted.\n",
    "    - Formula: Format its text as LaTeX.\n",
    "    - Table: Format its text as HTML.\n",
    "    - All Others (Text, Title, etc.): Format their text as Markdown.\n",
    "4. Constraints: Original text, sorted by reading order\n",
    "5. Output: Single JSON object.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd4e04e8-a18d-42e3-a73d-6ee973da96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造输入\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image_path},\n",
    "            {\"type\": \"text\", \"text\": prompt}\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc66ebf0-0881-439c-bd89-8a0e078934c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理输入\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45dbde41-11be-4145-84bc-bd3abbe47c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# 生成结果\n",
    "generated_ids = model.generate(** inputs, max_new_tokens=24000)\n",
    "generated_ids_trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
    "output_text = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eea86dc-c87f-40e9-9da3-df7eb5defb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"bbox\": [26, 10, 1044, 42], \"category\": \"Text\", \"text\": \"执行推理代码后, `print(output_text)`会在 Notebook 的“输出区”直接显示 JSON 格式的结果。\"}, {\"bbox\": [31, 105, 1030, 135], \"category\": \"List-item\", \"text\": \"* 找到所有\\\"category\\\"不是\\\"Picture\\\"的元素（图片无文字），直接读取对应的\\\"text\\\"字段即可。\"}, {\"bbox\": [31, 163, 1200, 239], \"category\": \"List-item\", \"text\": \"* 示例中：\\\"Title\\\"的文字是# Introduction to Machine Learning, \\\"Text\\\"的文字是正文内容，直接复制粘贴就能用。\"}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 打印结果\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587da006-1639-4ae3-a8d7-bb6455fc106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dots_ocr",
   "language": "python",
   "name": "dots_ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
